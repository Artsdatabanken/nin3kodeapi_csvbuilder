{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0241de5-a1af-42a5-b3ce-849006c93c8c",
   "metadata": {},
   "source": [
    "# Indeks\n",
    "\n",
    "* [Subsett av datasett](#Subset-av-datasett)\n",
    "* [Hovedtype.csv](#Hente-hovedtype.csv/json)\n",
    "* [Lag csv av Type-fanen](#Lage-csv-av-Type-fanen)\n",
    "* [Lag csv av mapping TG---HT---GT](#HTG---HT---GT-(kode-kode_kode))\n",
    "* [Hovedtypegruppe.csv](#Hovedtypegruppe.csv)\n",
    "* [Type - HTG (link via tk2)](#Type---HTG-(link-via-tk2))\n",
    "* [Hovedtype](#Hovedtype)\n",
    "* [Grunntyper.json](##Grunntyper.csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3e24f8-95ad-443c-b945-e6a5d15fba90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies:\n",
    "#-----------------\n",
    "#pip install pandas\n",
    "#pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35ad8c3",
   "metadata": {},
   "source": [
    "# Laster aktuelt regneark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b21358",
   "metadata": {},
   "outputs": [],
   "source": [
    "#regnearkfil = 'inn_data/NiN3.0_Tot_e15_20231009_import_kodebase.xlsx'\n",
    "regnearkfil = 'inn_data/NiN3.0_Tot_e15_20231123_import_kodebase.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ec1006",
   "metadata": {},
   "source": [
    "# Excel, type-fane til dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1119338-dbcf-48f7-94cd-8c89b4f6d902",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Se første linjer av fanen 'typer'\n",
    "        ### Dependency : openpyxl\n",
    "import pandas as pd\n",
    "#def load_nin3_typer:\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.mode.chained_assignment = None\n",
    "nin3_typer = pd.read_excel(regnearkfil, \n",
    "                        sheet_name='Typer', \n",
    "                        #sheet_name='HT_trinntest',\n",
    "                        na_filter = False, \n",
    "                        converters={'9 HT':str, \n",
    "                                    '11 GT': str,\n",
    "                                    'NiN 2 kode':str,\n",
    "                                    '10 GT/kE':str})#Denne kolonnen må leses inn som str for å ikke miste ledende nuller\n",
    "nin3_typer_orig = nin3_typer.copy(deep=True)\n",
    "nin3_typer.rename(columns={\n",
    "    '3 AbC': 'Ecosystnivå',\n",
    "    '4 kat1': 'Typekategori',\n",
    "    '5 kat2': 'Typekategori2',\n",
    "    '6 kat3': 'Typekategori3',\n",
    "    '7 HTG': 'Hovedtypegruppe',\n",
    "    '8 Pk': 'Prosedyrekategori',\n",
    "    '9 HT': 'Hovedtype'\n",
    "    }, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semikolon -sjekk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nin3_typer_sk = nin3_typer.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "# Iterate over each column in the dataframe\n",
    "for column in nin3_typer_sk.columns:\n",
    "    # Check if the column contains a semicolon (;)\n",
    "    if nin3_typer_sk[column].astype(str).str.contains(';').any():\n",
    "        # Get the rows where the semicolon (;) is present\n",
    "        rows_with_semicolon = nin3_typer_sk[nin3_typer_sk[column].astype(str).str.contains(';')]\n",
    "        # Print the [Langkode] of the rows and the name of the column\n",
    "        for index, row in rows_with_semicolon.iterrows():\n",
    "            print(f\"[Langkode]: {row['Langkode']}, Column: {column}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Støttemetoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sjekk_unikhet(df: pd.DataFrame, kolonne: str):\n",
    "    # Controlling uniqueness of Kode column\n",
    "    #--------------------------------------\n",
    "    # group the dataframe by the 'Kode' column and count the number of occurrences of each Kode\n",
    "    kode_counts = df.groupby(kolonne).size().reset_index(name='count')\n",
    "    # filter the resulting dataframe to only include rows where the count of each Kode is greater than 1\n",
    "    kode_counts_filtered = kode_counts[kode_counts['count'] > 1]\n",
    "    # display the resulting dataframe\n",
    "    if kode_counts_filtered.empty:\n",
    "        print(f\"\\tIngen duplikater i kolonnen {kolonne}\")\n",
    "    else:\n",
    "        print(\"\\tFant følgende duplikater i kolonnen {kolonne}:\\n\\n\")\n",
    "        print(kode_counts_filtered)\n",
    "    # Empty dataframe = no duplicates in Kode column"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4f9ede5-423f-452c-8eb5-3874d42f8a7c",
   "metadata": {},
   "source": [
    "## Hente Type.csv/json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75300379-3654-43e0-8516-4b9d512cba4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hovedtype csv\n",
    "import numpy as np\n",
    "typer = nin3_typer[['Ecosystnivå', 'Typekategori', 'Typekategori2']]#.unique()\n",
    "typer2 = typer.groupby(['Ecosystnivå','Typekategori', 'Typekategori2']).count().reset_index()\n",
    "#typer2.replace(0, np.nan, inplace=True) # BYTTER UT int 0-verdi med NaN (blank string i csv, null i json)\n",
    "typer2['Kode'] = typer2['Ecosystnivå'].map(str)+'-'+typer2['Typekategori'].map(str)+'-'+typer2['Typekategori2'].map(str)\n",
    "typer2.to_csv('ut_data/type.csv', index=False, sep=\";\") # NaN blir blank string i csv\n",
    "#typer2.to_json('ut_data/type.json', orient=\"table\", index=False) # NaN blir null i json, orient: tablestruktur istedenfor seriesstuktur"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13eb0b1e-9eae-486b-8b67-83a68824f897",
   "metadata": {},
   "source": [
    "## Hovedtypegruppe.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8552f5b0-2937-4040-a2e6-a54172f6d611",
   "metadata": {},
   "outputs": [],
   "source": [
    "hovedtypegrupper = nin3_typer[['Typekategori2','Hovedtypegruppe', 'Hovedtypegruppenavn', 'Typekategori3']]\n",
    "hovedtypegrupper = hovedtypegrupper.applymap(lambda x: x.strip() if isinstance(x, str) else x) #Setter alle kolonner til string\n",
    "hovedtypegrupper['Kode'] = hovedtypegrupper['Typekategori2'].map(str)+'-'+hovedtypegrupper['Hovedtypegruppe'].map(str)\n",
    "hovedtypegrupper['Typekategori3'] = hovedtypegrupper['Typekategori3'].replace('', '0').fillna('0') # BYTTER UT tomme verdier med 0 på Typekategori3\n",
    "\n",
    "# Convert all columns to string type for consistency\n",
    "hovedtypegrupper = hovedtypegrupper.astype(str)\n",
    "\n",
    "# Replace NaN values with a consistent value\n",
    "hovedtypegrupper = hovedtypegrupper.fillna('0')\n",
    "\n",
    "hovedtypegrupper2 = hovedtypegrupper.drop_duplicates()\n",
    "hovedtypegrupper2.to_csv('ut_data/hovedtypegrupper.csv', index=False, sep=\";\")\n",
    "\n",
    "\n",
    "# Controlling uniqueness of Kode column\n",
    "#--------------------------------------\n",
    "# group the dataframe by the 'Kode' column and count the number of occurrences of each Kode\n",
    "kode_counts = hovedtypegrupper2.groupby('Kode').size().reset_index(name='count')\n",
    "# filter the resulting dataframe to only include rows where the count of each Kode is greater than 1\n",
    "kode_counts_filtered = kode_counts[kode_counts['count'] > 1]\n",
    "# display the resulting dataframe\n",
    "print(kode_counts_filtered)\n",
    "# Empty dataframe = no duplicates in Kode column\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a21d1b1-8ee3-4d2f-bbf3-3d6fdd4dc9a2",
   "metadata": {},
   "source": [
    "## Type - HTG (link via tk2)\n",
    "### (type_ecosystnivaa, type_Tk, type_tk2, HTG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch all kodecolumns for Type and HTG\n",
    "typer_htg_0 = nin3_typer[['Ecosystnivå', 'Typekategori', 'Typekategori2', 'Hovedtypegruppe']] \n",
    "typer_htg_0 = typer_htg_0.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "typer_htg_0[\"typekode\"] = typer_htg_0['Ecosystnivå'].map(str)+'-'+typer_htg_0['Typekategori'].map(str)+'-'+typer_htg_0['Typekategori2'].map(str)\n",
    "typer_htg_0[\"thgkode\"] = typer_htg_0['Typekategori2'].map(str)+'-'+typer_htg_0['Hovedtypegruppe'].map(str)\n",
    "typer_htg = typer_htg_0.iloc[:, -2:] # select last two columns (typekode, thgkode)\n",
    "typer_htg = typer_htg.groupby(['typekode', 'thgkode']).count().reset_index()\n",
    "#typer_htg\n",
    "typer_htg.to_csv('ut_data/type_htg_mapping.csv', index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hovedtype & \n",
    "# HTG<>HT-mapping, \n",
    "forsøk på fix av duplikatproblem 2023-11-21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht0 = nin3_typer[['Hovedtype', 'Prosedyrekategori', 'Hovedtypegruppe', 'Hovedtypenavn', 'HTGKode']]\n",
    "ht0 = ht0.applymap(lambda x: x.strip() if isinstance(x, str) else x)# Removing whitespace\n",
    "ht0 = ht0.astype(str)# setting all to type string\n",
    "ht1 = ht0\n",
    "#ht1 = ht0.dropna(subset=['Hovedtypenavn'])\n",
    "#ht1 = ht0.drop(ht1[(ht1['Hovedtypenavn'] == '')].index)\n",
    "#ht1 = ht1[['Hovedtype', 'Prosedyrekategori', 'Hovedtypegruppe', 'Hovedtypenavn']]\n",
    "#ht1['Kode'] = ht1['Hovedtypegruppe'].map(str)+'-'+ht1['Prosedyrekategori'].map(str)+'-'+ht1['Hovedtype'].map(str)+ ht1['HTGKode'].str[0]\n",
    "ht1['Kode'] = ht1['HTGKode'].str[0]+ht1['Hovedtypegruppe'].map(str)+'-'+ht1['Prosedyrekategori'].map(str)+'-'+ht1['Hovedtype'].map(str)\n",
    "ht1.drop_duplicates(subset=['Kode','Hovedtypenavn'], inplace=True)\n",
    "ht1.drop(ht1[pd.isna(ht1['Hovedtypenavn'])].index, inplace=True)#Fjerne rader uten Hovedtypenavn for str type\n",
    "ht0 = nin3_typer[['Hovedtype', 'Prosedyrekategori', 'Hovedtypegruppe', 'Hovedtypenavn', 'HTGKode']]\n",
    "ht0 = ht0.applymap(lambda x: x.strip() if isinstance(x, str) else x)  # Removing whitespace\n",
    "ht0 = ht0.astype(str)  # setting all to type string\n",
    "ht1 = ht0\n",
    "ht1['Kode'] = ht1['HTGKode'].str[0] + ht1['Hovedtypegruppe'].map(str) + '-' + ht1['Prosedyrekategori'].map(str) + '-' + ht1['Hovedtype'].map(str)\n",
    "ht1.drop_duplicates(subset=['Kode', 'Hovedtypenavn'], inplace=True)\n",
    "ht1 = ht1[ht1['Hovedtypenavn'].str.len() > 0]  # Drop rows where string length of Hovedtypenavn-value is 0\n",
    "ht1_sorted = ht1.sort_values(by=['Kode', 'HTGKode'], ascending=True)\n",
    "\n",
    "ht1_sorted.to_csv('ut_data/hovedtype.csv', index=False, sep=\";\")\n",
    "#Getting mapping file HTG<>HT\n",
    "htg_ht = ht1_sorted[['Kode', 'HTGKode']].rename(columns={'Kode':'HTKode'})\n",
    "htg_ht.to_csv('ut_data/hovedtypegruppe_hovedtype_mapping.csv', index=False, sep=\";\")\n",
    "ht1_sorted = ht1_sorted.reindex(columns=['Kode', 'Hovedtypenavn', 'Hovedtypegruppe', 'Prosedyrekategori', 'Hovedtype', 'HTGKode'])\n",
    "ht1_sorted.to_csv('ut_data/hovedtype.csv', index=False, sep=\";\")\n",
    "#sjekk_unikhet(ht1_sorted, 'Kode')\n",
    "ht1_sorted\n",
    "print(ht1_sorted.count())\n",
    "#ht1_sorted\n",
    "\n",
    "# Kikker på sjekk_unikhet og printer rader for duplikat kode\n",
    "#rows = ht1_sorted[ht1_sorted['Kode'] == 'T-N-03N']\n",
    "#print(rows)\n",
    "#rows.to_csv('tmp/ht_rows.csv', index=False, sep=\";\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d51555f-6033-49f8-a499-60a7d988fb70",
   "metadata": {},
   "source": [
    "## Grunntyper.csv\n",
    "\n",
    "Filter: grunntyper['Grunntype'] != '0'\n",
    "\n",
    "!! Dette betyr at koder som 'A-0-01-0' i regnearket ikke blir med\n",
    "men det har heller ikke noen grunntypenavn så det er kanskje riktig?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef90cb89-5136-406a-b446-89e45a4fb81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#display(nin3_typer)\n",
    "grunntyper = nin3_typer[['Langkode','Hovedtypegruppe', 'Prosedyrekategori', 'Hovedtype', '11 GT', 'Grunntypenavn']]\n",
    "# TODO: Forsøk å hente fra nin3HTFIX dataframe\n",
    "#display(grunntyper.columns)\n",
    "#grunntyper2 = grunntyper[grunntyper['11 GT' != '0']] #feiler\n",
    "#grunntyper\n",
    "grunntyper.rename(columns = {'11 GT':'Grunntype'}, inplace = True)\n",
    "# Filtrer vekk \n",
    "grunntyper_vasket2 = pd.DataFrame(grunntyper[(grunntyper['Grunntype'] != '0') \n",
    "                     & (grunntyper['Grunntype'] != ' ') \n",
    "                     & (grunntyper['Grunntype'] != '-')\n",
    "                     & (grunntyper['Grunntypenavn'] != '-')\n",
    "                     & (grunntyper['Grunntypenavn'] != '')])\n",
    "grunntyper_vasket2['Kode'] = grunntyper_vasket2['Hovedtypegruppe'].map(str)+'-'+grunntyper_vasket2['Prosedyrekategori'].map(str)+'-'+grunntyper_vasket2['Hovedtype'].map(str)+'-'+grunntyper_vasket2['Grunntype'].map(str)\n",
    "#display(grunntyper_vasket2)\n",
    "#display(grunntyper_vasket)\n",
    "grunntyper_vasket2 = grunntyper_vasket2.sort_values(by=['Kode'])\n",
    "grunntyper_vasket2.to_csv('ut_data/grunntyper.csv', index=False, sep=\";\") # NaN blir blank string i csv\n",
    "\n",
    "\n",
    "# Sjekker om det mangler grunntypenavn i csv\n",
    "grunntyper_vasket2 = pd.read_csv('ut_data/grunntyper.csv', sep=';')\n",
    "grunntypenavn_diff = grunntyper_vasket2[~grunntyper_vasket2['Grunntypenavn'].isin(nin3_typer['Grunntypenavn'])]['Grunntypenavn']\n",
    "print(\"*** Sjekk: GTNavn som ikke finnes i grunntype.csv ***\")\n",
    "print(grunntypenavn_diff)\n",
    "\n",
    "\"\"\"\n",
    "# Controlling uniqueness of Kode column\n",
    "#--------------------------------------\n",
    "# group the dataframe by the 'Kode' column and count the number of occurrences of each Kode\n",
    "kode_counts = grunntyper_vasket2.groupby('Kode').size().reset_index(name='count')\n",
    "# filter the resulting dataframe to only include rows where the count of each Kode is greater than 1\n",
    "kode_counts_filtered = kode_counts[kode_counts['count'] > 1]\n",
    "# display the resulting dataframe\n",
    "print(kode_counts_filtered)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HT - GT mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# previous: htg_ht_gt_mapping_tmp = nin3_typer[['Typekategori2', 'Hovedtypegruppe', 'Hovedtype', 'Prosedyrekategori', '11 GT']]\n",
    "# Trying to use HTFix (where Hovedtype-column is modified for the Hovedtypes that gives duplicates)\n",
    "# TODO: impl\n",
    "htg_ht_gt_mapping_tmp = nin3_typer[['Typekategori2', 'Hovedtypegruppe', 'Hovedtype', 'Prosedyrekategori', '11 GT']]\n",
    "htg_ht_gt_mapping_tmp.rename(columns = {'11 GT':'Grunntype'}, inplace = True)\n",
    "\n",
    "htg_ht_gt_mapping =  htg_ht_gt_mapping_tmp\n",
    "#= pd.DataFrame(htg_ht_gt_mapping_tmp[(htg_ht_gt_mapping_tmp['Grunntype'] != '0') \n",
    "##                     & (htg_ht_gt_mapping_tmp['Grunntype'] != ' ') \n",
    " #                    & (htg_ht_gt_mapping_tmp['Grunntype'] != '-')])\n",
    "#display(htg_ht_gt_mapping)\n",
    "htg_mm = htg_ht_gt_mapping.groupby(['Typekategori2', 'Hovedtypegruppe', 'Hovedtype', 'Prosedyrekategori', 'Grunntype']).count().reset_index()\n",
    "htg_ht_gt_mapping['hovedtypegruppe_kode'] = htg_mm['Typekategori2'].map(str)+'-'+htg_mm['Hovedtypegruppe'].map(str)\n",
    "htg_ht_gt_mapping['hovedtype_kode'] = htg_ht_gt_mapping['hovedtypegruppe_kode'].str[0]+htg_mm['Hovedtypegruppe'].map(str)+'-'+htg_mm['Prosedyrekategori'].map(str)+'-'+htg_mm['Hovedtype'].map(str)\n",
    "htg_ht_gt_mapping['grunntype_kode'] = htg_mm['Hovedtypegruppe'].map(str)+'-'+htg_mm['Prosedyrekategori'].map(str)+'-'+htg_mm['Hovedtype'].map(str)+'-'+htg_mm['Grunntype'].map(str)\n",
    "htg_ht_gt_mapping2 = htg_ht_gt_mapping.drop(['Typekategori2', 'Hovedtypegruppe','Hovedtype', 'Prosedyrekategori', 'Grunntype'], axis=1)#.drop()\n",
    "#htg_ht_gt_mapping2.info()\n",
    "\n",
    "htg_ht_gt_mapping_non_null = htg_ht_gt_mapping2.drop(['hovedtypegruppe_kode'], axis=1)# dropping column 'hovedtypegruppe_kode', only used to create hovedtype_kode\n",
    "#htg_ht_gt_mapping_non_null\n",
    "htg_ht_gt_mapping_non_null.to_csv('ut_data/hovedtype_grunntype_mapping.csv', index=False, sep=\";\")\n",
    "\n",
    "#htg_ht_gt_mapping_non_null = htg_ht_gt_mapping2.dropna(how='all') #Drop the rows where all elements are missing\n",
    "#htg_ht_gt_mapping_non_null.to_csv('ut_data/hovedtype_grunntype_mapping.csv', index=False, sep=\";\") # NaN blir blank string i csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6febd6ce-ce03-4a12-b448-2444f4d626d3",
   "metadata": {},
   "source": [
    "## M005 liste (kode, navn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eee546-07ec-4bd9-892b-6d41a11e2464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "nin3_m005 = pd.read_excel(regnearkfil, \n",
    "                           sheet_name='M005', \n",
    "                           na_filter = False, \n",
    "                           converters={'11 GT': str})#Denne kolonnen må leses inn som str for å ikke miste ledende nuller\n",
    "#display(nin3_m005)\n",
    "\n",
    "# Henter m005 delkode, m005 kode(lang), m005 kortkode\n",
    "#m005_delkode_kode = nin3_typer[['M005', 'M005-kode']]\n",
    "#display(nin3_m005.columns)\n",
    "m005_kode_navn = nin3_m005[['M005-langkode', 'M005-navn', 'M005-kortkode']]\n",
    "m005_kode_navn.rename(columns = {'M005-langkode':'M005-kode'}, inplace = True)\n",
    "#display(m005_kode_navn.head())\n",
    "display(f\"before unique: {m005_kode_navn.shape[0]}\")\n",
    "\n",
    "m005_unik = m005_kode_navn.groupby(['M005-kode', 'M005-navn', 'M005-kortkode']).count().reset_index()\n",
    "m005_unik.sort_values('M005-kode')\n",
    "#display(f\"after unique-attempt(groupby): {m005_unik.shape[0]}\")\n",
    "#display(f\"Er m005-koder unik?: {m005_unik['M005-kode'].is_unique}\")\n",
    "m005_unik.to_csv('ut_data/M005.csv', index=False, sep=\";\")\n",
    "\n",
    "#display(m005_unik)\n",
    "\n",
    "###################### CHECK ##############################\n",
    "## Get the values in column 'M005-kode' that are not unique\n",
    "not_unique = m005_unik.loc[m005_unik.duplicated('M005-kode', keep=False), 'M005-kode'].unique()\n",
    "\n",
    "## Get the number of occurrences of each value in column 'M005-kode'\n",
    "counts = m005_unik['M005-kode'].value_counts()\n",
    "\n",
    "## Filter the counts to only include the non-unique values\n",
    "counts = counts[counts.index.isin(not_unique)]\n",
    "\n",
    "print(counts)\n",
    "print(\" (if you see 'Series([]..' all is ok!)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "537e8c06-c43d-484c-9f10-3a9c21301faa",
   "metadata": {},
   "source": [
    "## M005 <> GT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b2905f-3c38-4264-b696-287e886ad286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n3t = nin3_typer[['Hovedtypegruppe', 'Prosedyrekategori','Hovedtype','11 GT', 'Grunntypenavn','M005-kode', 'M005-navn']]\n",
    "\n",
    "n3t.rename(columns = {'11 GT':'Grunntype'}, inplace = True)\n",
    "n3t['grunntype_kode'] = n3t['Hovedtypegruppe'].map(str)+'-'+n3t['Prosedyrekategori'].map(str)+'-'+n3t['Hovedtype'].map(str)+'-'+n3t['Grunntype'].map(str)\n",
    "n3t_position  = n3t[['M005-kode', 'grunntype_kode', 'M005-navn', 'Grunntypenavn']]\n",
    "n3t_m005 = n3t_position[n3t_position['M005-kode'].str.strip().replace('', np.nan).notna()]\n",
    "n3t_m005.to_csv('ut_data/m005_grunntype_mapping.csv', index=False, sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVVENT DENNE FIX, sjekk først om alle M005 koder får en grunntypekode i forrige løsning.\n",
    "# Påbegynt fiks for GT <> M005 mapping\n",
    "\"\"\"\n",
    "n3t = nin3_typer[['Hovedtypegruppe', 'Prosedyrekategori','Hovedtype','10 ','11 GT', 'Grunntypenavn','M005-kode', 'M005-navn']]\n",
    "n3t2 = n3t[n3t['M005-kode'].str.contains('-', na=False)]\n",
    "n3t2['M005-kortkode'] = n3t['M005-kode'].str.split('-').str[-3:].str.join('-')\n",
    "\n",
    "n3t2\n",
    "n3t2.to_csv('ut_data/m005_grunntype_mapping_tmp.csv', index=False, sep=\";\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M005 <> HT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch 'M005-kode'\n",
    "nin3_typer = nin3_typer.astype(str) # setting all columns to string\n",
    "nin3_typer = nin3_typer.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "m005_HT = nin3_typer[['M005-kode', 'HTKode', 'Typekategori2']]\n",
    "m005_HT['HTKode'] = m005_HT['Typekategori2'].str[0]+m005_HT['HTKode'].str.replace('_', '-')\n",
    "m005_HT = m005_HT[m005_HT['M005-kode'].str.startswith('NiN-3.0')]\n",
    "m005_HT = m005_HT[['M005-kode', 'HTKode']]\n",
    "m005_HT = m005_HT.drop_duplicates(subset=['M005-kode', 'HTKode'])\n",
    "#m005_HT\n",
    "\n",
    "m005_HT.to_csv('ut_data/m005_hovedtype_mapping.csv', index=False, sep=\";\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4288a08",
   "metadata": {},
   "source": [
    "## M020 (kode, navn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34884480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "nin3_m020 = pd.read_excel(regnearkfil, \n",
    "                           sheet_name='M020', \n",
    "                           na_filter = False, \n",
    "                           converters={'11 GT': str})#Denne kolonnen må leses inn som str for å ikke miste ledende nuller\n",
    "nin3_m020 = nin3_m020.astype(str)\n",
    "nin3_m020 = nin3_m020.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "#display(nin3_m020)\n",
    "#how to get the unique values of a column that are not unique in pandas\n",
    "#https://stackoverflow.com/questions/47136436/how-to-get-the-unique-values-of-a-column-that-are-not-unique-in-pandas\n",
    "# Henter m020 delkode og m020 kode\n",
    "\n",
    "#m020_delkode_kode = nin3_typer[['M020', 'M020-kode']]\n",
    "#display(nin3_m020)\n",
    "m020_kode_navn = nin3_m020[['M020_kode', 'M020-navn', 'M020_kortkode']]\n",
    "m020_kode_navn.rename(columns = {'M020_kode':'M020-kode', 'M020_kortkode':'M020-kortkode'}, inplace = True)\n",
    "#display(m020_kode_navn.head()) # sikre at listen er unik\n",
    "m020_unik = m020_kode_navn.groupby(['M020-kode', 'M020-navn', 'M020-kortkode']).count().reset_index()\n",
    "m020_unik # fjern index og skriv til csv\n",
    "#order by M020-kode\n",
    "m020_unik_sorted = m020_unik.sort_values('M020-kode') \n",
    "#display(m020_unik_sorted.head())\n",
    "m020_unik_sorted.to_csv('ut_data/m020.csv', index=False, sep=\";\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "090bf699",
   "metadata": {},
   "source": [
    "## M020 <> grunntype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d431ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n3t = nin3_typer[['Hovedtypegruppe', 'Prosedyrekategori','Hovedtype','11 GT', 'Grunntypenavn','M020-kode', 'M020-navn']]\n",
    "\n",
    "n3t.rename(columns = {'11 GT':'Grunntype'}, inplace = True)\n",
    "n3t['grunntype_kode'] = n3t['Hovedtypegruppe'].map(str)+'-'+n3t['Prosedyrekategori'].map(str)+'-'+n3t['Hovedtype'].map(str)+'-'+n3t['Grunntype'].map(str)\n",
    "n3t_position  = n3t[['M020-kode', 'grunntype_kode', 'M020-navn', 'Grunntypenavn']]\n",
    "n3t_m020 = n3t_position[n3t_position['M020-kode'].str.strip().replace('', np.nan).notna()]\n",
    "n3t_m020.drop_duplicates(subset=['M020-kode', 'grunntype_kode'])\n",
    "n3t_m020 = n3t_m020[n3t_m020['M020-kode'].str.startswith('NiN-3.0')] # Fjerner rader som ikke starter med 'NiN-3.0' i [M020-kode]\n",
    "n3t_m020.to_csv('ut_data/m020_grunntype_mapping.csv', index=False, sep=\";\") \n",
    "n3t_m020.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M020 <> HT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nin3_typer = nin3_typer.astype(str) # setting all columns to string\n",
    "nin3_typer = nin3_typer.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "m020_HT = nin3_typer[['M020-kode', 'HTKode', 'HTGKode']]\n",
    "m020_HT['HTKode'] = m020_HT['HTGKode'].str[0]+m020_HT['HTKode'].str.replace('_', '-')\n",
    "m020_HT = m020_HT[m020_HT['M020-kode'].str.startswith('NiN-3.0')]#remove rows with empty or incorrect m020 values\n",
    "m020_HT = m020_HT[['M020-kode', 'HTKode']]#remove HTGKode\n",
    "m020_HT = m020_HT.drop_duplicates(subset=['M020-kode', 'HTKode'])\n",
    "m020_HT.to_csv('ut_data/m020_hovedtype_mapping.csv', index=False, sep=\";\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cf811c7",
   "metadata": {},
   "source": [
    "## m050 (kode, navn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7415109e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "nin3_m050 = pd.read_excel(regnearkfil, \n",
    "                           sheet_name='M050', \n",
    "                           na_filter = False, \n",
    "                           converters={'11 GT': str})#Denne kolonnen må leses inn som str for å ikke miste ledende nuller\n",
    "#how to get the unique values of a column that are not unique in pandas\n",
    "#https://stackoverflow.com/questions/47136436/how-to-get-the-unique-values-of-a-column-that-are-not-unique-in-pandas\n",
    "# Henter m020 delkode og m020 kode\n",
    "#display(nin3_m050.head())\n",
    "\n",
    "#m050_delkode_kode = nin3_typer[['M050', 'M050-kode']]\n",
    "m050_kode_navn = nin3_m050[['M050_kode', 'M050-navn', 'M050_kortkode']]\n",
    "#display(m050_kode_navn.head())\n",
    "m050_kode_navn.rename(columns = {'M050_kode':'M050-kode', 'M050_kortkode':'M050-kortkode'}, inplace = True)\n",
    "#display(m050_kode_navn.head()) # sikre at listen er unik\n",
    "m050_unik = m050_kode_navn.groupby(['M050-kode', 'M050-navn', 'M050-kortkode']).count().reset_index()\n",
    "m050_unik # fjern index og skriv til csv\n",
    "#order by M020-kode\n",
    "m050_unik_sorted = m050_unik.sort_values('M050-kode') \n",
    "m050_unik_sorted.to_csv('ut_data/m050.csv', index=False, sep=\";\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "517d89f9",
   "metadata": {},
   "source": [
    "## m050 <> grunntype mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40f5eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n3t = nin3_typer[['Hovedtypegruppe', 'Prosedyrekategori','Hovedtype','11 GT', 'Grunntypenavn','M050-kode', 'M050-navn']]\n",
    "\n",
    "n3t.rename(columns = {'11 GT':'Grunntype'}, inplace = True)\n",
    "n3t['grunntype_kode'] = n3t['Hovedtypegruppe'].map(str)+'-'+n3t['Prosedyrekategori'].map(str)+'-'+n3t['Hovedtype'].map(str)+'-'+n3t['Grunntype'].map(str)\n",
    "n3t_position  = n3t[['M050-kode', 'grunntype_kode', 'M050-navn', 'Grunntypenavn']]\n",
    "n3t_m050 = n3t_position[n3t_position['M050-kode'].str.strip().replace('', np.nan).notna()]\n",
    "n3t_m050 = n3t_m050[n3t_m050['M050-kode'].str.startswith('NiN-3.0')] # Fjerner rader som ikke starter med 'NiN-3.0' i [M020-kode]\n",
    "#n3t_m005\n",
    "n3t_m050.to_csv('ut_data/m050_grunntype_mapping.csv', index=False, sep=\";\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M050 <> hovedtype mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nin3_typer = nin3_typer.astype(str) # setting all columns to string\n",
    "nin3_typer = nin3_typer.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "m050_HT = nin3_typer[['M050-kode', 'HTKode','HTGKode']]\n",
    "m050_HT['HTKode'] = m050_HT['HTGKode'].str[0]+m050_HT['HTKode'].str.replace('_', '-') #Ny HTkode (Kat2 in front)\n",
    "m050_HT = m050_HT[m050_HT['M050-kode'].str.startswith('NiN-3.0')]\n",
    "m050_HT = m050_HT.drop_duplicates(subset=['M050-kode', 'HTKode'])\n",
    "m050_HT.to_csv('ut_data/m050_hovedtype_mapping.csv', index=False, sep=\";\")\n",
    "m050_HT.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a24a049",
   "metadata": {},
   "source": [
    "## TypeKlasser <> Langkode (typeklasser_langkode.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7625ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "typer_lk = nin3_typer[['Ecosystnivå', 'Typekategori', 'Typekategori2', 'Hovedtypegruppe', 'Hovedtypegruppenavn','Hovedtype', 'Prosedyrekategori','Langkode']]#.unique()\n",
    "#typer2.replace(0, np.nan, inplace=True) # BYTTER UT int 0-verdi med NaN (blank string i csv, null i json)\n",
    "typer_lk['Type_kode'] = typer2['Ecosystnivå'].map(str)+'-'+typer2['Typekategori'].map(str)+'-'+typer2['Typekategori2'].map(str)\n",
    "typer_lk['Hovedtypegruppe_kode'] = typer_lk['Typekategori2'].map(str)+'-'+typer_lk['Hovedtypegruppe'].map(str)\n",
    "typer_lk['Hovedtype_kode'] = typer_lk['Hovedtypegruppe'].map(str)+'-'+typer_lk['Prosedyrekategori'].map(str)+'-'+typer_lk['Hovedtype'].map(str)\n",
    "typeklasser_langkode = typer_lk[['Type_kode', 'Hovedtypegruppe_kode', 'Hovedtype_kode', 'Langkode']]\n",
    "#rows = typeklasser_langkode[typeklasser_langkode['Hovedtype_kode'] == 'A-0-0']\n",
    "#print(rows)\n",
    "typeklasser_langkode.to_csv('ut_data/typeklasser_langkode_mapping.csv', index=False, sep=\";\") # NaN blir blank string i csv\n",
    "#rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceec735",
   "metadata": {},
   "source": [
    "## Grunntype - Variabeltrinn (<i>grunntype_variabeltrinn_mapping.csv</i>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aac6d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "gt_vt = nin3_typer[nin3_typer['10 GT/kE'] == 'G'][['Hovedtypegruppe', 'Prosedyrekategori','Hovedtype','11 GT', 'Definisjonsgrunnlag','oLkM']]\n",
    "gt_vt.rename(columns = {'11 GT':'Grunntype'}, inplace = True)\n",
    "# Filtrer vekk \n",
    "gt_vt_1 = pd.DataFrame(gt_vt[(gt_vt['Grunntype'] != '0') \n",
    "                     & (gt_vt['Grunntype'] != ' ') \n",
    "                     & (gt_vt['Grunntype'] != '-')])\n",
    "# replace [,] with \"\" in Definisjonsgrunnlag\n",
    "gt_vt_1['Definisjonsgrunnlag'] = gt_vt_1['Definisjonsgrunnlag'].str.replace('[\\[\\]]', '')\n",
    "gt_vt_1['GTKode'] = gt_vt_1['Hovedtypegruppe'].map(str)+'-'+gt_vt_1['Prosedyrekategori'].map(str)+'-'+gt_vt_1['Hovedtype'].map(str)+'-'+gt_vt_1['Grunntype'].map(str)\n",
    "gt_vt_1 = gt_vt_1.dropna(subset=['Definisjonsgrunnlag'])\n",
    "new_gt_vt_rows = []\n",
    "gt_vt_1[['Varkode2', 'Trinn']] = None\n",
    "gt_vt_1= gt_vt_1.loc[:, ['GTKode', 'Varkode2', 'Trinn', 'Definisjonsgrunnlag']].drop_duplicates()\n",
    "# iterate over each row in the dataframe\n",
    "for index, row in gt_vt_1.iterrows():\n",
    "    # check if the '10 Målesk' column has multiple values separated by comma\n",
    "    if('T-E-05-01' in row['GTKode']):\n",
    "      print(row['GTKode'])\n",
    "    if ',' in row['Definisjonsgrunnlag']:\n",
    "        # if yes, split the values and create a new row for each value\n",
    "        values = row['Definisjonsgrunnlag'].split(',')\n",
    "        for value in values:\n",
    "            new_row = row.copy()\n",
    "            value = value.replace('[', '').replace(']', '').strip()\n",
    "            \n",
    "            #Now split on _\n",
    "            vk2andTrinns = value.split('_')\n",
    "            if(len(vk2andTrinns) > 1): \n",
    "                vk2 = vk2andTrinns[0].upper()\n",
    "                trinns = vk2andTrinns[1]\n",
    "                for char in trinns:\n",
    "                    # do something with the character\n",
    "                    #print(char)\n",
    "                    char_row = new_row.copy()\n",
    "                    char_row['Varkode2'] = vk2\n",
    "                    char_row['Trinn'] = vk2+\"-\"+char.strip()\n",
    "                    new_gt_vt_rows.append(char_row)\n",
    "            else:\n",
    "                char_row = new_row.copy()\n",
    "                new_row['Varkode2'] = vk2\n",
    "                new_row['Trinn'] = ''\n",
    "                new_gt_vt_rows.append(new_row)\n",
    "    else:\n",
    "        new_row = row.copy()\n",
    "        value = value.replace('[', '').replace(']', '').strip()\n",
    "            #Now split on _\n",
    "        vk2andTrinns = value.split('_')\n",
    "        vk2 = vk2andTrinns[0].upper()\n",
    "        if(len(vk2andTrinns) > 1): # IF grunntype has trinn\n",
    "            trinns = vk2andTrinns[1]\n",
    "            for char in trinns:\n",
    "                # do something with the character\n",
    "                #print(char)\n",
    "                char_row = new_row.copy()\n",
    "                char_row['Varkode2'] = vk2\n",
    "                char_row['Trinn'] = vk2+\"-\"+char.strip()\n",
    "                new_gt_vt_rows.append(char_row)\n",
    "        else:\n",
    "            char_row = new_row.copy()\n",
    "            char_row['Varkode2'] = vk2\n",
    "            char_row['Trinn'] = ''\n",
    "            new_gt_vt_rows.append(char_row)\n",
    "\n",
    "# create a new dataframe from the list of new rows\n",
    "new_gt_vt = pd.DataFrame(new_gt_vt_rows)\n",
    "new_gt_vt['Trinn'] = new_gt_vt['Trinn'].str.replace('-', '_')\n",
    "# Add grunntypekode\n",
    "#new_gt_vt['GTKode'] = new_gt_vt['Hovedtypegruppe'].map(str)+'-'+new_gt_vt['Prosedyrekategori'].map(str)+'-'+new_gt_vt['Hovedtype'].map(str)+'-'+new_gt_vt['Grunntype'].map(str)\n",
    "new_gt_vt = new_gt_vt.loc[:, ['GTKode', 'Varkode2', 'Trinn', 'Definisjonsgrunnlag']].drop_duplicates()\n",
    "\n",
    "\n",
    "variabelnavnkode_varkode2 = pd.read_csv('inn_data/variabelnavnkode_varkode2.csv', sep=\";\")\n",
    "new_gt_vt_done = pd.merge(new_gt_vt, variabelnavnkode_varkode2, left_on='Varkode2', right_on='Varkode2_kopi', how='left')\n",
    "new_gt_vt_done.drop(['Varkode2_kopi'], axis=1, inplace=True)\n",
    "new_gt_vt_done.rename(columns={'Kortkode':'Variabelnavn_kortkode'}, inplace=True)\n",
    "new_gt_vt_done.to_csv('ut_data/grunntype_variabeltrinn_mapping.csv', index=False, sep=\";\") # NaN blir blank string i csv\n",
    "new_gt_vt_done.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c4e558",
   "metadata": {},
   "source": [
    "## Hovedtyper <> variabeltrinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ea84a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class varkode2_Trinn:\n",
    "    Variabelnavn_kortkode:str = ''\n",
    "    Trinn:str = ''\n",
    "    Varkode2:str = ''\n",
    "\n",
    "variabelnavnkode_varkode2 = pd.read_csv('inn_data/variabelnavnkode_varkode2.csv', sep=\";\")\n",
    "def handle_definisjonsgrunnlag(dg)->list:\n",
    "    trinnlist = []\n",
    "    dg = dg.replace('[', '').replace(']', '').replace('(‒)','').strip()\n",
    "    dg = dg.replace('-', '').strip()\n",
    "    v2_ts = dg.split(\",\")\n",
    "    for v2t in v2_ts:\n",
    "        v2t_sp = v2t.split(\"_\")\n",
    "        varkode2 = v2t_sp[0].upper()\n",
    "        variabelnavnkode_varkode2_row = variabelnavnkode_varkode2[variabelnavnkode_varkode2['Varkode2_kopi'] == varkode2]\n",
    "        Variabelnavn_kortkode = ''\n",
    "        if not variabelnavnkode_varkode2_row.empty:\n",
    "            Variabelnavn_kortkode = variabelnavnkode_varkode2_row['Kortkode'].values[0]\n",
    "        if len(v2t_sp) == 2:\n",
    "            for t in v2t_sp[1]:\n",
    "                    vt = varkode2_Trinn()\n",
    "                    vt.Variabelnavn_kortkode = Variabelnavn_kortkode\n",
    "                    vt.Trinn = varkode2.strip()+\"_\"+t.strip()\n",
    "                    vt.Varkode2 = varkode2.strip()\n",
    "                    trinnlist.append(vt)\n",
    "        else:\n",
    "            vt = varkode2_Trinn()\n",
    "            vt.Variabelnavn_kortkode = Variabelnavn_kortkode,\n",
    "            vt.Varkode2 = varkode2\n",
    "            trinnlist.append(vt)\n",
    "    return trinnlist\n",
    "\n",
    "#def find_\n",
    "#def \n",
    "variabeltrinnList = []\n",
    "# prepare a class with all output fields\n",
    "\n",
    "# fetch dataframe with varkode2<>variabelnavn_kortkode mapping\n",
    "variabelnavnkode_varkode2 = pd.read_csv('inn_data/variabelnavnkode_varkode2.csv', sep=\";\")\n",
    "\n",
    "# Fetch the columns + definfisjonsgrunnlag\n",
    "ht_variabeltrinn = nin3_typer_orig[(nin3_typer_orig['9 HT'] != '0') & (nin3_typer_orig['11 GT']=='0')][['7 HTG', '8 Pk','9 HT', 'Definisjonsgrunnlag', '5 kat2']]\n",
    "## Create a valid Hovedtypekode from the row values\n",
    "ht_variabeltrinn['HTKode'] = ht_variabeltrinn['5 kat2'].str[0]+ht_variabeltrinn['7 HTG'].map(str)+'-'+ht_variabeltrinn['8 Pk'].map(str)+'-'+ht_variabeltrinn['9 HT'].map(str)\n",
    "ht_variabeltrinn_filtered = ht_variabeltrinn[(ht_variabeltrinn['Definisjonsgrunnlag'] != '') & (ht_variabeltrinn['Definisjonsgrunnlag'] != '-')]\n",
    "# dataframe for storing trinn-results\n",
    "ht_trinn_df = pd.DataFrame({\n",
    "    'HTkode': [],\n",
    "    'Varkode2': [],\n",
    "    'Trinn': [],\n",
    "    'Variabelnavn_kortkode': [],\n",
    "    'Definisjonsgrunnlag': []\n",
    "})\n",
    "for index, row in ht_variabeltrinn_filtered.iterrows():\n",
    "    # Create a dataframe series for each trinn given in Definisjonsgrunnlag\n",
    "    varkode_trinnList = handle_definisjonsgrunnlag(row['Definisjonsgrunnlag'])\n",
    "\n",
    "    for vt in varkode_trinnList:\n",
    "        # add the new row to the final dataframe\n",
    "        new_row = {\n",
    "            'HTkode': row['HTKode'], \n",
    "            'Varkode2': vt.Varkode2, \n",
    "            'Trinn': vt.Trinn,\n",
    "            'Variabelnavn_kortkode': vt.Variabelnavn_kortkode if str(vt.Variabelnavn_kortkode) != \"('',)\" else '',\n",
    "            'Definisjonsgrunnlag': row['Definisjonsgrunnlag']\n",
    "        }\n",
    "        # add the new row to the final dataframe\n",
    "        #ht_trinn_df.append(new_row, ignore_index=True)\n",
    "        ht_trinn_df.loc[len(ht_trinn_df)] = new_row\n",
    "        #ht_trinn_df = pd.concat([ht_trinn_df, new_series], ignore_index=True)\n",
    "\n",
    "# save dataframe to CSV file with ; as separator\n",
    "ht_trinn_df.to_csv('ut_data/hovedtype_variabeltrinn_mapping.csv', sep=';', index=False)\n",
    "#ht_trinn_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebea51bf",
   "metadata": {},
   "source": [
    ".. Hovedtypegruppe <> variabeltrinn (Er ikke neon [Definisjonsgrunnlag]/trinn for hovedtypegruppe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326daad5",
   "metadata": {},
   "source": [
    "## Klargjør konvertering (v3.0 -> v2.3) \n",
    "Koder, Objekttyper v2.3 (hjelpemetoder for konvertering v3.0 -> v2.3)\n",
    "\n",
    "--> Function: get_23_koder() -> dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dbd852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import csv\n",
    "import os\n",
    "import urllib.parse\n",
    "\n",
    "# Read sqlite query results into a pandas DataFrame\n",
    "con = sqlite3.connect(\"nin2prod.db\")\n",
    "query = \"\"\"\n",
    "    Select distinct KodeName, 'Type' as Klasse from Kode where VersionId in (select id from NiNVersion where Navn ='2.3')\n",
    "    UNION\n",
    "    Select distinct KodeName, 'Variabel' as Klasse from VariasjonKode where VersionId in (select id from NiNVersion where Navn ='2.3')\n",
    "    Order by Klasse\"\"\"\n",
    "df = pd.read_sql_query(query, con)\n",
    "\n",
    "# Verify that result of SQL query is stored in the dataframe\n",
    "\n",
    "con.close()\n",
    "df.to_csv('inn_data/2_3_koder_fra_sqlite_prod.csv', sep=';', index=False)\n",
    "\n",
    "# Load v2.3 koder to dict\n",
    "koder23 = {}\n",
    "with open('inn_data/2_3_koder_fra_sqlite_prod.csv', newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, delimiter=';', quotechar='\"')\n",
    "    koder = []\n",
    "    for row in reader:\n",
    "        if ',' in row['KodeName']:\n",
    "            # do something if the string contains a comma\n",
    "            kode_list = row['KodeName'].split(',')\n",
    "            for kode in kode_list:\n",
    "                lookupkode = kode.lower().strip() #lager lookupkolonne som lowercase siden kode fra excel er ..\n",
    "                # ..ukorrekt i bruk av  i bruk små og store bokstaver\n",
    "                if lookupkode.startswith(\"na \"):\n",
    "                    lookupkode = lookupkode.replace(\"na \", \"\")\n",
    "                koder23[lookupkode.strip()] = {\"KondeName\":row['KodeName'].strip(), \"Klasse\":row['Klasse']}\n",
    "                #koder23[kode.strip()] = row['Klasse']\n",
    "        else:\n",
    "            # do something else if the string does not contain a comma\n",
    "            lookupkode = row['KodeName'].lower().strip() #lager lookupkolonne som lowercase siden kode fra excel er ..\n",
    "                # ..ukorrekt i bruk av  i bruk små og store bokstaver\n",
    "            if lookupkode.startswith(\"na \"):\n",
    "                lookupkode = lookupkode.replace(\"na \", \"\")\n",
    "            koder23[lookupkode.strip()] = {\"KodeName\":row['KodeName'].strip(), \"Klasse\":row['Klasse']}\n",
    "\n",
    "# Write koder23 to a text file in the tmp directory\n",
    "with open(os.path.join('tmp', 'koder23.txt'), 'w') as f:\n",
    "    output = []\n",
    "    for key, value in koder23.items():\n",
    "        output.append(f\"{key}: {value}\\n\")\n",
    "    f.write(\"\".join(output))\n",
    "\n",
    "\n",
    "# TODO: Hvis koden ikke får tregg forsøk oppslag med å bytt \"-\" med \n",
    "def create_v23_variabel_url(kode):\n",
    "    if(kode==\"V12\"):\n",
    "        print(\"V12\")\n",
    "    kode = kode.lower()\n",
    "    var_url = 'https://nin-kode-api.artsdatabanken.no/v2.3/variasjon/hentkode/'\n",
    "    type_url = 'https://nin-kode-api.artsdatabanken.no/v2.3/koder/hentkode/'\n",
    "    result = {}\n",
    "    if koder23.get(kode):\n",
    "        kodeentry = koder23.get(kode)\n",
    "        if kodeentry[\"Klasse\"] == 'Variabel':\n",
    "            result[\"kode23\"]=kodeentry['KodeName']\n",
    "            result[\"url\"]=f\"{var_url}{urllib.parse.quote(kodeentry['KodeName'])}\" \n",
    "            return result\n",
    "        elif kodeentry[\"Klasse\"] == 'Type':\n",
    "            result[\"kode23\"]=kodeentry['KodeName']\n",
    "            result[\"url\"]=f\"{type_url}{urllib.parse.quote(kodeentry['KodeName'])}\" \n",
    "            return result\n",
    "        else:\n",
    "            return {}\n",
    "    else:\n",
    "        return {}\n",
    "    \n",
    "def make_list_nin2kode(nin2kode):\n",
    "    reslist = []\n",
    "    n2list = nin2kode.split(',')\n",
    "    first = n2list[0]\n",
    "    for n2 in n2list:\n",
    "        if n2.isdigit():\n",
    "            reslist.append(first.split('-')[0]+'-'+n2)\n",
    "        else:\n",
    "            reslist.append(n2)\n",
    "    return reslist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf556e6",
   "metadata": {},
   "source": [
    "## Konvertering (HTG)\n",
    "!! SETT 9 HT = 0 !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb1bbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "htg0 = nin3_typer_orig[['3 AbC', '4 kat1', '5 kat2', '6 kat3','7 HTG', '8 Pk','9 HT', '11 GT', 'NiN 2 kode', 'FP', 'SP']]\n",
    "#display(htg0)\n",
    "# remove heading and tailing spaces from all columns\n",
    "htg0 = htg0.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "htg0_1 = htg0[\n",
    "    (htg0['5 kat2'] != 'LA') & # holdes midlertidig utenfor\n",
    "    (htg0['4 kat1'] != 'LI') & # holdes midlertidig utenfor\n",
    "    (htg0['9 HT'] == '0') & \n",
    "    (htg0['11 GT']=='0')][['3 AbC', '4 kat1', '5 kat2', '6 kat3','7 HTG', '8 Pk','9 HT', '11 GT', 'NiN 2 kode', 'FP', 'SP']]\n",
    "#htg1 = htg0[(htg0['NiN 2 kode'] != '-') & (htg0['NiN 2 kode']!='')]\n",
    "htg1 = htg0_1[htg0_1['NiN 2 kode'] != '-']\n",
    "htg1 = htg1[htg1['NiN 2 kode'] != '']\n",
    "htg1['HTGkode'] = htg1['5 kat2'].map(str)+'-'+htg1['7 HTG'].map(str)\n",
    "htg2 = htg1[['HTGkode', 'NiN 2 kode', 'FP', 'SP']]\n",
    "htg2 = htg2.rename(columns={'NiN 2 kode': 'forrigekode'})\n",
    "htg2['Klasse'] = 'HTG'\n",
    "htg2.to_csv('tmp/htg_konv.csv', sep=';', index=False)\n",
    "\n",
    "\n",
    "# Open the file as dictreader\n",
    "htg_rows = []\n",
    "\n",
    "with open('tmp/htg_konv.csv', newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, delimiter=';')\n",
    "    for row in reader:\n",
    "        new = {} # new dict to store the new row\n",
    "        new['HTGkode']=row['HTGkode']\n",
    "        new['FP']=row['FP']\n",
    "        new['SP']=row['SP']\n",
    "        new['Klasse']=row['Klasse']\n",
    "        result = create_v23_variabel_url(row['forrigekode'])\n",
    "        new['forrigekode']=result['kode23']\n",
    "        new['url']=result['url']\n",
    "        if new['url'] =='':# bytter siste \"-\" med \"_\" og prøver igjen\n",
    "            kode = row['forrigekode'].rsplit('-', 1)\n",
    "            kode = '_'.join(kode)\n",
    "            result = create_v23_variabel_url(kode)\n",
    "            new['forrigekode']=result['kode23']\n",
    "            new['url']=result['url']\n",
    "        if new['url'] =='':\n",
    "            print(f\"Fant ikke url for {kode}\")\n",
    "        htg_rows.append(new)\n",
    "\n",
    "# Creating konvertering csv for HTG\n",
    "with open('ut_data/konvertering_htg_v30.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['HTGkode','forrigekode','FP','SP','Klasse', 'url']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames, delimiter=';')\n",
    "    writer.writeheader()\n",
    "    writer.writerows(htg_rows)\n",
    "    print(f\"File written to {csvfile.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1b5420",
   "metadata": {},
   "source": [
    "## Konvertering (HT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7044e12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ht0 = nin3_typer_orig.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "ht0_0 = ht0[\n",
    "    (ht0['5 kat2'] != 'LA') & # holdes midlertidig utenfor\n",
    "    (ht0['4 kat1'] != 'LI') & # holdes midlertidig utenfor\n",
    "    (ht0['NiN 2 kode'] != 'ny') &\n",
    "    (ht0['9 HT'] != '0') & \n",
    "    (ht0['11 GT']=='0')][['3 AbC', '4 kat1', '5 kat2', '6 kat3','7 HTG', '8 Pk','9 HT', '11 GT', 'NiN 2 kode', 'FP', 'SP']]\n",
    "# remove heading and tailing spaces from all columns\n",
    "\n",
    "ht0_0 = ht0_0[ht0_0['NiN 2 kode'] != '-']\n",
    "ht0_0 = ht0_0[ht0_0['NiN 2 kode'] != '']\n",
    "ht1 = ht0_0\n",
    "ht1['HTkode'] = ht1['5 kat2'].str[0]+ht1['7 HTG'].map(str)+'-'+ht1['8 Pk'].map(str)+'-'+ht1['9 HT'].map(str)\n",
    "\n",
    "ht2 = ht1[['HTkode', 'NiN 2 kode', 'FP', 'SP']]\n",
    "ht2 = ht2.rename(columns={'NiN 2 kode': 'forrigekode'})\n",
    "ht2['Klasse'] = 'HT'\n",
    "ht2.to_csv('tmp/ht_konv.csv', sep=';', index=False)\n",
    "\n",
    "ht_rows = []\n",
    "\n",
    "#reading the csv file with DictReader\n",
    "with open('tmp/ht_konv.csv', newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, delimiter=';')\n",
    "    all_rows = []\n",
    "    #check rows for multiple nin2koder\n",
    "    for r in reader:\n",
    "        if \",\" in r.get(\"forrigekode\"):\n",
    "            n2list = make_list_nin2kode(r.get(\"forrigekode\"))\n",
    "            for n2 in n2list:\n",
    "                new_row = r.copy()\n",
    "                new_row[\"forrigekode\"] = n2.strip()\n",
    "                all_rows.append(new_row)\n",
    "    \n",
    "    #loop over rows\n",
    "    for row in all_rows:\n",
    "        new = {} # new dict to store the new row\n",
    "        new['HTkode']=row['HTkode']\n",
    "        new['FP']=row['FP']\n",
    "        new['SP']=row['SP']\n",
    "        new['Klasse']=row['Klasse']\n",
    "        result = create_v23_variabel_url(row['forrigekode'])\n",
    "        new['forrigekode']=result.get('kode23')\n",
    "        new['url']=result.get('url')\n",
    "        if not new.get('url'):# bytter siste \"-\" med \"_\" og prøver igjen\n",
    "            kode = row['forrigekode'].rsplit('-', 1)\n",
    "            kode = '_'.join(kode)\n",
    "            result = create_v23_variabel_url(kode)\n",
    "            new['forrigekode']=result.get('kode23')\n",
    "            new['url']=result.get('url')\n",
    "        # Sjekker om excel-kolonnen forrigekode (nin 2 koden) hadde match i koder23-dictonary \n",
    "        if not new.get('url'):\n",
    "            new['forrigekode']=row['forrigekode'] \n",
    "            print(f\"Fant ikke url for NiN2kode:{row['forrigekode']}\")\n",
    "        ht_rows.append(new)\n",
    "\n",
    "# Creating konvertering csv for HT\n",
    "with open('ut_data/konvertering_ht_v30.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['HTkode','forrigekode','FP','SP','Klasse', 'url']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames, delimiter=';')\n",
    "    writer.writeheader()\n",
    "    writer.writerows(ht_rows)\n",
    "    print(f\"File written to {csvfile.name}\")    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a669a634",
   "metadata": {},
   "source": [
    "## Konvertering (GT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0697d3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt0 = nin3_typer_orig.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "gt0_0 = gt0[\n",
    "    (gt0['5 kat2'] != 'LA') & # holdes midlertidig utenfor\n",
    "    (gt0['4 kat1'] != 'LI') & # holdes midlertidig utenfor\n",
    "    (gt0['NiN 2 kode'] != 'ny') &\n",
    "    (gt0['NiN 2 kode'] != '-') &\n",
    "    (gt0['NiN 2 kode'] != '') &\n",
    "    (gt0['11 GT']!='0')][['3 AbC', '4 kat1', '5 kat2', '6 kat3','7 HTG', '8 Pk','9 HT', '11 GT', 'NiN 2 kode', 'FP', 'SP']]\n",
    "\n",
    "gt0_0['GTKode'] = gt0_0['7 HTG'].map(str)+'-'+gt0_0['8 Pk'].map(str)+'-'+gt0_0['9 HT'].map(str)+'-'+gt0_0['11 GT'].map(str)\n",
    "gt1 = gt0_0[['GTKode', 'NiN 2 kode', 'FP', 'SP']]\n",
    "gt1 = gt1.rename(columns={'NiN 2 kode': 'forrigekode'})\n",
    "gt1[\"FP\"]=gt1[\"FP\"].replace('?', '')\n",
    "gt1[\"SP\"]=gt1[\"SP\"].replace('?', '')\n",
    "gt1['Klasse'] = 'GT'\n",
    "gt1.to_csv('tmp/gt_konv.csv', sep=';', index=False)\n",
    "\n",
    "\n",
    "gt_rows = []\n",
    "with open('tmp/gt_konv.csv', newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, delimiter=';')\n",
    "    all_rows = []\n",
    "    #check rows for multiple nin2koder\n",
    "    for r in reader:\n",
    "        if \",\" in r.get(\"forrigekode\"):\n",
    "            n2list = make_list_nin2kode(r.get(\"forrigekode\"))\n",
    "            for n2 in n2list:\n",
    "                new_row = r.copy()\n",
    "                new_row[\"forrigekode\"] = n2.strip()\n",
    "                all_rows.append(new_row)\n",
    "    \n",
    "    #loop over rows\n",
    "    for row in all_rows:\n",
    "        new = {} # new dict to store the new row\n",
    "        new['GTKode']=row['GTKode']\n",
    "        new['FP']=row['FP']\n",
    "        new['SP']=row['SP']\n",
    "        new['Klasse']=row['Klasse']\n",
    "        result = create_v23_variabel_url(row['forrigekode'])\n",
    "        new['forrigekode']=result.get('kode23')\n",
    "        new['url']=result.get('url')\n",
    "        if not new.get('url'):# bytter siste \"-\" med \"_\" og prøver igjen\n",
    "            kode = row['forrigekode'].rsplit('-', 1)\n",
    "            kode = '_'.join(kode)\n",
    "            result = create_v23_variabel_url(kode)\n",
    "            new['forrigekode']=result.get('kode23')\n",
    "            new['url']=result.get('url')\n",
    "        # Sjekker om excel-kolonnen forrigekode (nin 2 koden) hadde match i koder23-dictonary \n",
    "        if not new.get('url'):\n",
    "            new['forrigekode']=row['forrigekode'] \n",
    "            print(f\"Fant ikke url for NiN2kode:{row['forrigekode']}\")\n",
    "        gt_rows.append(new)\n",
    "\n",
    "# Creating konvertering csv for GT\n",
    "with open('ut_data/konvertering_gt_v30.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['GTKode','forrigekode','FP','SP','Klasse', 'url']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames, delimiter=';')\n",
    "    writer.writeheader()\n",
    "    writer.writerows(gt_rows)\n",
    "    print(f\"File written to {csvfile.name}\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
